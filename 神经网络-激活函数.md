### 神经网络-激活函数

###### 1. **softmax函数**

**softmax用于多分类过程中**，它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类, 假设我们有一个数组，V，Vi表示V中的第i个元素，那么这个元素的softmax值就是
$$
S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}
$$
<img src="https://pic2.zhimg.com/80/v2-87b232ab0e292a536e94b73952caadd0_hd.jpg" alt="img" style="zoom: 80%;" />

**Loss定义为交叉熵**

<img src="https://www.zhihu.com/equation?tex=L_i%3D-log%28%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_j%7Be%5Ej%7D%7D%29" alt="[公式]" style="zoom:80%;" />

我们定义选到yi的概率是

<img src="https://www.zhihu.com/equation?tex=P_%7By_i%7D%3D%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_j%7Be%5Ej%7D%7D" alt="[公式]" style="zoom:80%;" />

然后我们求Loss对每个权重矩阵的偏导，应用链式法则*（中间推导省略）*，**最后结果的形式非常的简单，只要将算出来的概率的向量对应的真正结果的那一维减1，就可以了**

<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7BL_i%7D%7D%7B%5Cpartial%7Bf_%7By_i%7D%7D%7D%3D%5Cfrac%7B%5Cpartial%28-%5Cln%28%5Cfrac%7Be%5E%7Bf_%7By_%7Bi%7D%7D%7D%7D%7B%5Csum_%7Bj%7De%5E%7B%7Bj%7D%7D%7D%29%29%7D%7B%5Cpartial%7Bf_%7By_i%7D%7D%7D%3DP_%7Bf_%7By_i%7D%7D-1" alt="[公式]" style="zoom:80%;" />